{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fasttext1.ipynb",
      "provenance": [],
      "mount_file_id": "1JAfWRZex7N1gP2HMjdWQZebCsMZRthYc",
      "authorship_tag": "ABX9TyOZzTVLliBTHKZgms38OImr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma-saloni/Articles/blob/master/Fasttext1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!pip install word2number\n",
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aByzVMdkzqAJ",
        "outputId": "25439cc3-63e2-4ec4-b691-7e114f10768c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.2)\n",
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=beff3aea39d80836f467cac9c7d0b1a0d2525996dd51696290e490707b2583f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.0.58-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 66.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85452 sha256=ac55d29d01d703d087d88315a9bf7a8bafba6aa7f47f095315e1fe5af53cd6e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.58 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wffusyCytsx",
        "outputId": "7f440b34-acc3-44fa-cbba-8bf6f7aa9be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import string\n",
        "string.punctuation\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import unidecode\n",
        "from word2number import w2n\n",
        "import contractions\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "# load spacy model, can be \"en_core_web_sm\" as well\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SusBhh-CzXYG",
        "outputId": "bb0b55f8-f886-4a9b-ce7e-b18b6bb1eca2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake = pd.read_csv('/content/drive/MyDrive/Thesis/gossipcop_fake.csv')\n",
        "df_real = pd.read_csv('/content/drive/MyDrive/Thesis/gossipcop_real.csv')\n",
        "df_fake['labelML']=0\n",
        "df_real['labelML']=1\n",
        "df= df_fake.head(50).append(df_real.head(50))\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "bwskIeYazYL6"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjYdaIs51j87",
        "outputId": "3c0e25d3-e0be-44d0-879c-166297245c86"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'news_url', 'title', 'tweet_ids', 'labelML'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df)"
      ],
      "metadata": {
        "id": "o2VUVYCL1q1i"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1= df.drop(['tweet_ids', 'news_url','id'], axis=1)"
      ],
      "metadata": {
        "id": "jwscw5FG1t8P"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP Preprocessing\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# NLP Preprocess - gensim.utils.simple_preprocess(doc, deacc=False, min_len=2, max_len=15)[source]\n",
        "# Convert a document into a list of tokens.\n",
        "# This lowercases, tokenizes, de-accents (optional). – the output are final tokens = unicode strings, that won’t be processed any further.\n",
        "\n",
        "df1.iloc[:, 0] = df1.iloc[:, 0].apply(lambda x: ' '.join(simple_preprocess(x)))"
      ],
      "metadata": {
        "id": "hdd1tdzS2HmB"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prefixing each row of the category column with '__label__' 0;10 all rows. same for column. \n",
        "#---------df1.iloc[:, 0] = df1.iloc[1:, 0].apply(lambda x: '__label__' + x)\n",
        "#print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0VW4-_B3Ool",
        "outputId": "8ed6f391-94be-4846-eddc-2cdf4fcb1eaa"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                title  labelML\n",
            "0   did miley cyrus and liam hemsworth secretly ge...        0\n",
            "1   paris jackson cara delevingne enjoy night out ...        0\n",
            "2   celebrities join tax march in protest of donal...        0\n",
            "3   cindy crawford daughter kaia gerber wears wig ...        0\n",
            "4              full list of oscar nominations variety        0\n",
            "..                                                ...      ...\n",
            "95  michael buble and wife luisana lopilato welcom...        1\n",
            "96      selena gomez is going to keep her blonde hair        1\n",
            "97            netflix new releases coming in february        1\n",
            "98  halsey calls iggy azalea king moron and calls ...        1\n",
            "99  delilah opens up about son suicide and heartbr...        1\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h6wPx2906bxr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " #df = df.loc[:,\"title\"]\n",
        " # just for loc practice, ignore.\n",
        "\n",
        " X_train - This includes your all independent variables,these will be used to train the model, also as we have specified the test_size = 0.4, this means 60% of observations from your complete data will be used to train/fit the model and rest 40% will be used to test the model.\n",
        "\n",
        "2). X_test - This is remaining 40% portion of the independent variables from the data which will not be used in the training phase and will be used to make predictions to test the accuracy of the model.\n",
        "\n",
        "3). y_train - This is your dependent variable which needs to be predicted by this model, this includes category labels against your independent variables, we need to specify our dependent variable while training/fitting the model.\n",
        "\n",
        "4). y_test - This data has category labels for your test data, these labels will be used to test the accuracy between actual and predicted categories.\n"
      ],
      "metadata": {
        "id": "U0I2iZpj83sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prefixing each row of the category column with '__label__' 0;10 all rows. same for column. \n",
        "df1.iloc[:49, 0] = df1.iloc[1:, 0].apply(lambda x: '__label__0 ' + x)\n",
        "df1.iloc[50:, 0] = df1.iloc[1:, 0].apply(lambda x: '__label__1 ' + x)\n",
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6LGL-V67EHw",
        "outputId": "a57b80ad-f3c7-4da9-d71e-61833051830d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                title  labelML\n",
            "0                                                 NaN        0\n",
            "1   __label__0 paris jackson cara delevingne enjoy...        0\n",
            "2   __label__0 celebrities join tax march in prote...        0\n",
            "3   __label__0 cindy crawford daughter kaia gerber...        0\n",
            "4   __label__0 full list of oscar nominations variety        0\n",
            "..                                                ...      ...\n",
            "95  __label__1 michael buble and wife luisana lopi...        1\n",
            "96  __label__1 selena gomez is going to keep her b...        1\n",
            "97  __label__1 netflix new releases coming in febr...        1\n",
            "98  __label__1 halsey calls iggy azalea king moron...        1\n",
            "99  __label__1 delilah opens up about son suicide ...        1\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.reset_index(drop=True, inplace=True)\n",
        "X, y = df1.iloc[:, 1:], df1['labelML']\n",
        "\n",
        "# Create the training and test sets #IMP: use stratify when dataset is not balanced X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3)\n",
        "#https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
        "\n",
        "# Instantiate the XGBClassifier: xg_cl\n",
        "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
        "\n",
        "# Fit the classifier to the training set\n",
        "xg_cl.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set: preds\n",
        "preds = xg_cl.predict(X_test)\n",
        "\n",
        "# Compute the accuracy: accuracy\n",
        "accuracy = float(np.sum(preds == y_test)) / y_test.shape[0]\n",
        "print(\"accuracy: %f\" % (accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRG_kuxYD8ld",
        "outputId": "9ae6c14c-ef79-4c67-f081-77538b27b6f9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df1\n",
        "df2 = df2.reindex(columns=['labelML', 'title'])\n",
        "#print(df1)"
      ],
      "metadata": {
        "id": "k8Q5iYqKFV5l"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df2, test_size=0.2)"
      ],
      "metadata": {
        "id": "uPFqJirScaCL"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the CSV file as a text file to train/test the classifier\n",
        "import csv #needed\n",
        "train[['labelML', 'title']].to_csv('train.txt', \n",
        "                                          index = False, \n",
        "                                          sep = ' ',\n",
        "                                          header = None, \n",
        "                                          quoting = csv.QUOTE_NONE, \n",
        "                                          quotechar = \"\", \n",
        "                                          escapechar = \" \")\n",
        "\n",
        "test[['labelML', 'title']].to_csv('test.txt', \n",
        "                                     index = False, \n",
        "                                     sep = ' ',\n",
        "                                     header = None, \n",
        "                                     quoting = csv.QUOTE_NONE, \n",
        "                                     quotechar = \"\", \n",
        "                                     escapechar = \" \")"
      ],
      "metadata": {
        "id": "XS3912OVE1hT"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import fasttext\n",
        "# Training the fastText classifier\n",
        "model = fasttext.train_supervised('train.txt', wordNgrams = 2)\n",
        "\n",
        "# Evaluating performance on the entire test file\n",
        "model.test('test.txt')                      \n",
        "\n",
        "# Predicting on a single input\n",
        "test['labelML'] = test['labelML'].astype(str)\n",
        "model.predict(test.iloc[6, 0])\n",
        "\n",
        "# Save the trained model\n",
        "#model.save_model('model.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmeXA3LwwCJZ",
        "outputId": "e57ffad5-253d-4d0f-d0a7-79953b90fde6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__1',), array([0.50024968]))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2JYv7k5xkh9",
        "outputId": "3b05afdb-d508-4171-aa7c-2c20412902aa"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8     0\n",
            "70    1\n",
            "82    1\n",
            "28    0\n",
            "63    1\n",
            "0     0\n",
            "5     0\n",
            "50    1\n",
            "81    1\n",
            "4     0\n",
            "Name: labelML, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}